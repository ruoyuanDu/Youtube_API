{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab50f3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import spacy\n",
    "from spacy.matcher import Matcher \n",
    "from spacy.tokens import Span \n",
    "from spacy import displacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3b0aa40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2376 entries, 0 to 2375\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   videoId       2376 non-null   object \n",
      " 1   categoryId    2376 non-null   object \n",
      " 2   category      2376 non-null   object \n",
      " 3   title         2376 non-null   object \n",
      " 4   viewCount     2375 non-null   float64\n",
      " 5   likeCount     2342 non-null   float64\n",
      " 6   commentCount  2336 non-null   float64\n",
      " 7   publishedAt   2376 non-null   object \n",
      " 8   channelId     2376 non-null   object \n",
      " 9   description   2376 non-null   object \n",
      " 10  channelTitle  2376 non-null   object \n",
      " 11  regionCode    2376 non-null   object \n",
      "dtypes: float64(3), object(9)\n",
      "memory usage: 241.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet('/home/fagabby/working/YoutubeProject/project/db/01-2022_10-2022.parquet')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c908c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewCount_avg = df.groupby('category')['viewCount'].mean()\n",
    "df_smm = viewCount_avg.to_frame(name='avg_view')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2782d2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_smm.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8d83a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_counts = df.groupby('category')['videoId'].count()\n",
    "df_smm['video_cnts'] = video_counts.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8a3dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "like_cnts = df.groupby('category')['likeCount'].mean()\n",
    "df_smm['avg_likes'] = like_cnts.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b4dca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmmnt_cnts = df.groupby('category')['commentCount'].mean()\n",
    "df_smm['avg_cmmnts'] = cmmnt_cnts.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ae865d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=df_smm, x='category', y='video_cnts', \n",
    "            order=df_smm.sort_values('video_cnts', ascending=False).category)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Total uploaded number of videos per category')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d002aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=df_smm, x='category', y='avg_view', \n",
    "            order=df_smm.sort_values('avg_view', ascending=False).category)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Average number of views per category')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8232da",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=df_smm, x='category', y='avg_likes', \n",
    "            order=df_smm.sort_values('avg_likes', ascending=False).category)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Average number of likes per category')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670c2bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=df_smm, x='category', y='avg_cmmnts', \n",
    "            order=df_smm.sort_values('avg_cmmnts', ascending=False).category)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Average number of cmmnts per category')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb327f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank category by each column\n",
    "df_smm.set_index('category').rank(ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5959bb4d",
   "metadata": {},
   "source": [
    "<font size=2>This table shows the ranking of categories based on different metrics. Comedy has the highest average_views, average_likes, and average_comments, even though the total number of comedy videos is small. Entertainment category has the highest number of uploaded videos. If someone would want to make videos about some product reviews, I would suggest choosing one category that has less number of uploaded videos (less competitions), but relatively higher comments, likes and views (viewers like to watch and interate with the youtuber). <font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db68614",
   "metadata": {},
   "source": [
    "### Group by publishing month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce789be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month'] = pd.DatetimeIndex(df['publishedAt']).month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5f880c",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_cnts = df.groupby('month')['viewCount'].mean()\n",
    "df_month = view_cnts.to_frame(name='avg_view')\n",
    "df_month.reset_index(inplace=True)\n",
    "df_month['avg_likes'] = df.groupby('month')['likeCount'].mean()\n",
    "df_month['avg_cmmnts'] = df.groupby('month')['commentCount'].mean()\n",
    "df_month.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c24ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='month', y='avg_view', data=df_month, markers=True)\n",
    "plt.title('monthly view counts per video')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9819b0e8",
   "metadata": {},
   "source": [
    "<font size=2>It seems that Feburary has extremly high views, while after August, the view counts steadly decreases. <font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09cfadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='month', y='avg_likes', data=df_month, markers=True)\n",
    "plt.title('monthly like counts per video')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42489b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='month', y='avg_cmmnts', data=df_month, markers=True)\n",
    "plt.title('monthly commenting counts per video')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5252f2",
   "metadata": {},
   "source": [
    "<font size=2>Basically there are less people wathching videos in September and October from the plot of \"monthly view counts per video\", but the commenting is more active. <font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9280f06d",
   "metadata": {},
   "source": [
    "### NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30bb4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract category Auto $ Vehicles\n",
    "df_auto = df[df['category']=='Autos & Vehicles'].reset_index()\n",
    "auto_title_list = df_auto['title'].to_list()\n",
    "\n",
    "# extract category Scienc & Technology\n",
    "df_tech = df[df['category']=='Science & Technology'].reset_index()\n",
    "tech_title_list = df_tech['title'].to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35337875",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('tagsets')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6f3a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Autos\n",
    "tokenizer = nltk.RegexpTokenizer(r\"\\w{2,}\")\n",
    "auto_words = tokenizer.tokenize(' '.join(auto_title_list))\n",
    "\n",
    "# for technology\n",
    "tokenizer = nltk.RegexpTokenizer(r\"\\w{2,}\")\n",
    "tech_words = tokenizer.tokenize(' '.join(tech_title_list))\n",
    "\n",
    "#nltk corpus containing all english words\n",
    "english_words = nltk.corpus.words.words()\n",
    "#set of stopwrods\n",
    "stop_words = set(stopwords.words('english'))\n",
    "extra_words = ['shorts', 'review', '2022', 'india', 'hindi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8ff92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_clean_words = [w for w in auto_words if w.lower() not in stop_words]\n",
    "auto_clean_words = [w for w in auto_clean_words if w in english_words]\n",
    "auto_clean_words = [w for w in auto_clean_words if w.lower() not in extra_words]\n",
    "\n",
    "tech_clean_words = [w for w in tech_words if w.lower() not in stop_words]\n",
    "tech_clean_words = [w for w in tech_clean_words if w in english_words]\n",
    "tech_clean_words = [w for w in tech_clean_words if w.lower() not in extra_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2786a899",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_fd = nltk.FreqDist(w.lower() for w in auto_clean_words)\n",
    "wc = WordCloud().generate_from_frequencies(auto_fd)\n",
    "plt.figure(figsize=[12, 7])\n",
    "plt.imshow(wc, interpolation='bilinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac19ffea",
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_fd = nltk.FreqDist(w.lower() for w in tech_clean_words)\n",
    "wc = WordCloud().generate_from_frequencies(tech_fd)\n",
    "plt.figure(figsize=[12, 7])\n",
    "plt.imshow(wc, interpolation='bilinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42737ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean(text_list):\n",
    "    clean_list = []\n",
    "    for text in text_list:\n",
    "        # remove all non-word characters\n",
    "        t = re.sub('\\W', repl=' ', string=text)\n",
    "        clean_list.append(' '.join(t.split()).lower())\n",
    "    return clean_list\n",
    "\n",
    "auto_title_clean = clean(auto_title_list)\n",
    "tech_title_clean = clean(tech_title_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0e5ed9",
   "metadata": {},
   "source": [
    "<font size=5>Auto Brand Extraction<font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b84982",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['textcat'])\n",
    "auto_doc = nlp(auto_title_clean[3])\n",
    "displacy.render(auto_doc, style='dep', jupyter=True)\n",
    "for tok in auto_doc:\n",
    "    print(tok.text, \"-->\",tok.dep_, \"-->\",tok.pos_, \"-->\", tok.ent_type_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f23e08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = [\n",
    "    [{'POS':'PROPN', 'OP':'?'}],\n",
    "    [{'ENT_TYPE':'DATE'}],\n",
    "    [{'POS':'PROPN', 'OP':'?'}]\n",
    "]\n",
    "\n",
    "def find_names(text):\n",
    "    doc = nlp(text)\n",
    "    matcher = Matcher(nlp.vocab) \n",
    "    matcher.add(\"matching_1\", pattern) \n",
    "    matches = matcher(doc)\n",
    "    name = []\n",
    "    for i in range(len(matches)):\n",
    "        span = doc[matches[i][1]:matches[i][2]] \n",
    "        name.append(span)\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4b30bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['textcat'])\n",
    "auto_doc = nlp(auto_title_clean[6])\n",
    "displacy.render(auto_doc, style='dep', jupyter=True)\n",
    "for tok in auto_doc:\n",
    "    print(tok.text, \"-->\",tok.dep_, \"-->\",tok.pos_, \"-->\", tok.ent_type_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d064d837",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_names = []\n",
    "for texts in auto_title_clean:\n",
    "    for t in find_names(texts):\n",
    "        title_names.append(t.text) #convert span type to str type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17d5f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_title_words = tokenizer.tokenize(' '.join(title_names))\n",
    "tech_fd = nltk.FreqDist(w for w in auto_title_words)\n",
    "wc = WordCloud().generate_from_frequencies(tech_fd)\n",
    "plt.figure(figsize=[12, 7])\n",
    "plt.imshow(wc, interpolation='bilinear')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e63a8ad",
   "metadata": {},
   "source": [
    "<font size='3'>Popular Auto brands are Toyota, BMW, Hyundai, Suzuki, Ford, Audi, Jeep, Tesla, Subaru, Nissan.<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d99ddcc",
   "metadata": {},
   "source": [
    "<font size=5>Tech Brand Extraction<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b677f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['textcat'])\n",
    "tech_doc = nlp(tech_title_clean[1])\n",
    "displacy.render(tech_doc, style='dep', jupyter=True)\n",
    "for tok in tech_doc:\n",
    "    print(tok.text, \"-->\",tok.dep_, \"-->\",tok.pos_, \"-->\", tok.ent_type_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d07855",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['textcat'])\n",
    "tech_doc = nlp(tech_title_clean[16])\n",
    "# displacy.render(tech_doc, style='dep', jupyter=True)\n",
    "for tok in tech_doc:\n",
    "    print(tok.text, \"-->\",tok.dep_, \"-->\",tok.pos_, \"-->\", tok.ent_type_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28b8bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_tech = [\n",
    "    [{'DEP':'aux', 'OP':'?'}],\n",
    "    [{'DEP':'compound', 'POS':'ADJ', 'OP':'{1}'}],\n",
    "    [{'DEP':'nsubj', 'POS':'PROPN', 'ENT_TYPE':{'IN':['ORG']}, 'OP':'?'}],\n",
    "    [{'DEP':'ROOT', 'POS':{'IN':['PROPN', 'VERB', 'NOUN']}, 'LOWER':{'NOT_IN':['review']}}],\n",
    "    [{'DEP':'compound', 'POS':'PROPN', 'ENT_TYPE':{'NOT_IN':['ORG', 'CARDINAL','ORDINAL']}}],\n",
    "    \n",
    "]\n",
    "\n",
    "def find_names(text):\n",
    "    doc = nlp(text)\n",
    "    matcher = Matcher(nlp.vocab) \n",
    "    matcher.add(\"matching_tech\", pattern_tech) \n",
    "    matches = matcher(doc)\n",
    "    name = []\n",
    "    for i in range(len(matches)):\n",
    "        span = doc[matches[i][1]:matches[i][2]] \n",
    "        name.append(span)\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4e5372",
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_title_names = []\n",
    "for texts in tech_title_clean:\n",
    "    for t in find_names(texts):\n",
    "        tech_title_names.append(t.text) #convert span type to str type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414fc67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_title_words = tokenizer.tokenize(' '.join(tech_title_names))\n",
    "tech_fd = nltk.FreqDist(w for w in tech_title_words)\n",
    "wc = WordCloud().generate_from_frequencies(tech_fd)\n",
    "plt.figure(figsize=[12, 7])\n",
    "plt.imshow(wc, interpolation='bilinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81029875",
   "metadata": {},
   "outputs": [],
   "source": [
    "<font size='3'>Popular Auto brands are Samsung Galaxy, Iphone, Pixel, Oneplus, Macbook, Vivo, Xiaomi, Motorola.<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9998cc1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c345a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36350a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9dcd06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff43cfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
